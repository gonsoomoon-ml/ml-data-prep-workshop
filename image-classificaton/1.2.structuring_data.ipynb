{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 1.2] 이미지 분류를 위한 폴더 구조 생성\n",
    "Download | **Structure** | Preprocessing | Train Model (4단계 중의 2/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 분류를 위한 폴더 구조\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TensorFlow 및 PyTorch, MXNet 대부분의 프레임워크는 수정을 통해 모든 파일 구조의 데이터를 수용할 수 있습니다.\n",
    "- 하지만, 이 같은 프레임워크가 모두 수용 가능한 파일 구조를 가지게 되면 모델 개발이 빨라 지게 됩니다. \n",
    "- 기본적으로 대부분의 프레임워크는 아래에 설명된 파일 구조에서 이미지 데이터를 찾습니다.\n",
    "이 노트북에서는 아래와 같은 구조를 만들어 보겠습니다.\n",
    "\n",
    "```\n",
    "+-- train\n",
    "|   +-- class_A\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|   +-- class_B\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|\n",
    "+-- val\n",
    "|   +-- class_A\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|   +-- class_B\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|\n",
    "+-- test\n",
    "|   +-- class_A\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|   +-- class_B\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "|       +-- filename.jpg\n",
    "```\n",
    "- COCO 데이터셋은 위와 같이 구성되지 않으므로 주석 데이타를 사용하여 위의 패턴과 일치하도록 만들겁니다.\n",
    "- **새 디렉토리 구조가 생성되면 원하는 프레임워크의 데이터 로드 툴을 사용하여 이미지 데이터에 대한 로딩 및 변환을 할 수 있습니다.** \n",
    "- 보통의 많은 예제들은 이러한 과정이 생략이 되어 있습니다. 하지만 현업에서 실제 작업을 할 시에는 이러한 과정을 해야하기에 여기서 배워 봄니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 노트북 요약\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 노트북에서는 샘플의 주석 및 카테고리 데이타를 로딩 합니다.\n",
    "- 데이터를 훈련, 검증 및 테스트 세트로 분할합니다. \n",
    "- 그런 다음 Python을 사용하여 새 폴더 구조를 만들고 파일을 올바른 세트 및 레이블 폴더에 복사합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 샘플 주석 (2750개) 및 카테고리 레이블 로딩\n",
    "___\n",
    "`sample_annos` 및 `category_labels` 파일은 이 시리즈 `1.1_download_data.ipynb`의 첫 번째 노트북에서 생성되었습니다. 여기에서 코드를 실행하기 전에 해당 노트북을 실행해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickled_data/sample_annos.pickle\", \"rb\") as f:\n",
    "    sample_annos = pickle.load(f)\n",
    "\n",
    "with open(\"pickled_data/category_labels.pickle\", \"rb\") as f:\n",
    "    category_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 셋을 훈련, 검증, 테스트 로 분리\n",
    "___\n",
    "- 데이터를 학습, 검증 및 테스트 분할로 나누어야 합니다. \n",
    "- 일반적인 분할 비율은 80/10/10입니다. \n",
    "- 우리의 이미지 분류 알고리즘은 처음 80%(훈련)에 대해 훈련하고 다음 10%(검증)로 각 에폭(Epoch)의 성능을 평가 합니다.\n",
    "- 마지막 10%(테스트)를 사용하여 모델의 최종 정확도 결과를 제공합니다. \n",
    "- 데이터를 분할하기 전에 분할 간의 클래스 분포가 대략 비례하도록 무작위로 섞는 것이 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_shape: \n",
      " (2200,)\n",
      "val_ids_shape: \n",
      " (275,)\n",
      "test_ids_shape: \n",
      " (275,)\n",
      "val_ids: \n",
      " [581722 181697 115859 446764 165141]\n",
      "train_ids: \n",
      " [168879 382564 210275 571938 518455]\n",
      "test_ids: \n",
      " [ 85288 466210 581855 324937 581749]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "image_ids = sorted(list(sample_annos.keys())) # 이미지 ID 리스트 추출\n",
    "np.random.shuffle(image_ids) \n",
    "\n",
    "first_80 = int(len(image_ids) * 0.8)\n",
    "next_10 = int(len(image_ids) * 0.9)\n",
    "train_ids, val_ids, test_ids = np.split(image_ids, [first_80, next_10])\n",
    "\n",
    "print(\"train_shape: \\n\", train_ids.shape)\n",
    "print(\"val_ids_shape: \\n\", val_ids.shape)\n",
    "print(\"test_ids_shape: \\n\", test_ids.shape)\n",
    "\n",
    "print(\"val_ids: \\n\", val_ids[0:5])\n",
    "print(\"train_ids: \\n\", train_ids[0:5])\n",
    "print(\"test_ids: \\n\", test_ids[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 새 폴더 구조를 만들고 이미지 파일을 복사합니다.\n",
    "___\n",
    "아래와 같은 순서로 코드가 동작 합니다.\n",
    "- data_structured 생성\n",
    "    - train, val, test 폴더 생성\n",
    "        - 카테고리 폴더 생성 \n",
    "            - 예: category_dir:  data_structured/train/giraffe\n",
    "        - 소스 파일을 타겟 경로로 복사                \n",
    "            - 소스파일 지정    \n",
    "                - 예: source_path:  data_sample_2750/000000132015.jpg\n",
    "            - 타겟경로 지정    \n",
    "                - 예: target_path:  data_structured/train/giraffe/000000132015.jpg\n",
    "            - 복사\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_structured is created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "unstruct_dir = Path(\"data_sample_2750\") \n",
    "struct_dir = Path(\"data_structured\") # 구조화된 폴더 이름\n",
    "\n",
    "if os.path.isdir(struct_dir): # 폴더 존재하면 삭제\n",
    "    shutil.rmtree(struct_dir)\n",
    "    print(f\"{struct_dir} is deleted\")\n",
    "\n",
    "struct_dir.mkdir(exist_ok=True, parents=True) # 폴더 생성    \n",
    "print(f\"{struct_dir} is created\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2200/2200 [00:00<00:00, 5334.89it/s]\n",
      "100%|██████████| 275/275 [00:00<00:00, 5508.81it/s]\n",
      "100%|██████████| 275/275 [00:00<00:00, 5442.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# train, val, test 세번 반복\n",
    "for name, split in zip([\"train\", \"val\", \"test\"], [train_ids, val_ids, test_ids]):\n",
    "    split_dir = struct_dir / name\n",
    "    split_dir.mkdir(exist_ok=True) # train, val, test 폴더 생성\n",
    "    for image_id in tqdm(split):\n",
    "        category_dir = split_dir / f'{category_labels[sample_annos[image_id][\"category_id\"]]}'\n",
    "        # print(\"category_dir: \", category_dir)\n",
    "        category_dir.mkdir(exist_ok=True) # category 폴더 생성\n",
    "        source_path = (unstruct_dir / sample_annos[image_id][\"file_name\"]).as_posix()\n",
    "        target_path = (category_dir / sample_annos[image_id][\"file_name\"]).as_posix()\n",
    "#         print(\"source_path: \", source_path)\n",
    "#         print(\"target_path: \", target_path)        \n",
    "        shutil.copy(source_path, target_path)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  만들어진 폴더를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_structured/test\n",
      "data_structured/test/giraffe\n",
      "data_structured/test/zebra\n",
      "data_structured/test/frog\n",
      "data_structured/test/elephant\n",
      "data_structured/test/bear\n",
      "data_structured/test/sheep\n",
      "data_structured/test/cat\n",
      "data_structured/test/cow\n",
      "data_structured/test/bird\n",
      "data_structured/test/dog\n",
      "data_structured/test/horse\n",
      "data_structured/train\n",
      "data_structured/train/giraffe\n",
      "data_structured/train/zebra\n",
      "data_structured/train/frog\n",
      "data_structured/train/elephant\n",
      "data_structured/train/bear\n",
      "data_structured/train/sheep\n",
      "data_structured/train/cat\n",
      "data_structured/train/cow\n",
      "data_structured/train/bird\n",
      "data_structured/train/dog\n",
      "data_structured/train/horse\n",
      "data_structured/val\n",
      "data_structured/val/giraffe\n",
      "data_structured/val/zebra\n",
      "data_structured/val/frog\n",
      "data_structured/val/elephant\n",
      "data_structured/val/bear\n",
      "data_structured/val/sheep\n",
      "data_structured/val/cat\n",
      "data_structured/val/cow\n",
      "data_structured/val/bird\n",
      "data_structured/val/dog\n",
      "data_structured/val/horse\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    " \n",
    "def listdirs(rootdir):\n",
    "    for path in Path(rootdir).iterdir():\n",
    "        if path.is_dir():\n",
    "            print(path)\n",
    "            listdirs(path)\n",
    " \n",
    "rootdir = 'data_structured'\n",
    "listdirs(rootdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 다음 과정\n",
    "- 선택한 프레임워크에서 이미지를 쉽게 로드할 수 있으므로 다음 단계는 프레임워크를 선택하는 것입니다. \n",
    "    - (1) SageMaker의 내장 알고리즘 \n",
    "    - (2) TensorFlow\n",
    "    - (3) PyTorch를 \n",
    "\n",
    "\n",
    "- 자세히 알고 싶은 프레임워크에 따라 다음 노트북을 선택할 수 있습니다. 데이터가 프레임워크에 로드되면 전처리, 파일 형식, 변환 및 데이터 증강을 다룹니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
