{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 2.1] SageMaker 내장 알고리즘을 위한 이미지 전처리 \n",
    "Download | Structure | **Preprocessing (Built-in)** | Train Model (Built-in) (4단계 중의 3/4)\n",
    "\n",
    "\n",
    "\n",
    "### [알림] <font coler=\"red\"> conda_mxnet_latest_p37 커널 </font> 과 함께 사용해야 합니다.\n",
    " \n",
    "* 이 노트북은 `1.1.download_data` 및 `1.2.structuring_data`로 시작하는 일련의 노트북의 일부입니다. 여기에서는 SageMaker의 내장 알고리즘을 위한 데이터 처리에 중점을 둘 것입니다. 이 시리즈의 다음 노트북은 '2.2.builtin_training'입니다.\n",
    "\n",
    "\n",
    "### 참고\n",
    "- 세이지 메이커 내장 이미지 분류 알고리즘 --> [SageMaker built-in Image Classification Algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/image-classification.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 노트북 요약\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 노트북에서는 SageMaker의 기본 제공 알고리즘에 대한 이미지 데이터 세트의 형식을 지정하는 다양한 방법을 살펴봅니다. \n",
    "    - (1) Application/x-image format\n",
    "    - (2) Application/x-recordio (권장 format)\n",
    "- 우리는 권장 포맷으로서 이미지 데이터 및 레이블이 포함된 던일 바이너리 파일인 .REC 파일(RecordIO 형식)을 생성 합니다.\n",
    "- RecordIO 형식 (.rec)인 파일을 S3에 업로드합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 환경 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카테고리 레이블 로딩\n",
    "\n",
    "`category_labels` 파일은 이 시리즈 `1.1.download_data.ipynb`의 첫 번째 노트북에서 생성되었습니다. 여기에서 코드를 실행하기 전에 해당 노트북을 실행해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import boto3\n",
    "import shutil\n",
    "import urllib\n",
    "import pickle\n",
    "import pathlib\n",
    "import sagemaker\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickled_data/category_labels.pickle\", \"rb\") as f:\n",
    "    category_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Application/x-image format\n",
    "___\n",
    "\n",
    "- 이 형식은 \"이미지 형식\" 또는 \"LST\" 형식이라고도 합니다. 이를 사용하면 데이터세트를 수정하거나 재구성할 필요가 없다는 이점이 있습니다. \n",
    "- 대신 훈련 세트 및 검증 세트에 대한 이미지의 매니페스트 파일을 생성합니다. (예: train.lst)\n",
    "- 이 두 매니페스트는 별도의 `.lst` 파일로, 각 이미지에 아래의 세 가지로 구성이 됩니다.\n",
    "    - (1) 고유 이미지 인덱스\n",
    "    - (2) 이미지의 카테고리 (레이블)\n",
    "    - (3) 기본 훈련 폴더의 이미지 파일에 대한 상대 경로\n",
    "    \n",
    "    \n",
    "- `.lst` 파일의 데이터는 탭으로 구분된 값에 있습니다.\n",
    "\n",
    "- 사용하기 가장 쉬운 형식이지만 SageMaker가 뒤에서 더 많은 작업을 수행해야 합니다. 이미지가 많은 데이터 세트의 경우 학습 시간이 더 오래 걸립니다. 더 적은 수의 이미지가 있는 데이터세트의 경우 성능 차이가 그렇게 뚜렷하지 않습니다.\n",
    "\n",
    "- 다음은 .LST 매니페스트 파일을 만드는 방법에 대한 두 가지 예입니다. \n",
    "    - Option 1: 하나는 자체 코드를 사용하고 \n",
    "    - Option 2:  MXNet의 정의된 스크립트를 사용합니다. \n",
    "        - 실제로 아래에서 .REC 파일을 생성시에는 옵션 2를 사용합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: 직접 코딩으로 생성한 the .LST files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bear': 0, 'bird': 1, 'cat': 2, 'cow': 3, 'dog': 4, 'elephant': 5, 'frog': 6, 'giraffe': 7, 'horse': 8, 'sheep': 9, 'zebra': 10}\n"
     ]
    }
   ],
   "source": [
    "category_ids = {name: idx for idx, name in enumerate(sorted(category_labels.values()))}\n",
    "print(category_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_lst_name = 'train.lst' ; val_lst_name = 'val.lst' ; test_lst_name = 'test.lst'\n",
    "\n",
    "\n",
    "def delete_file(file_name):\n",
    "    if os.path.isfile(file_name):\n",
    "        os.remove(file_name)\n",
    "        print(f\"{file_name} is deleted\")\n",
    "        \n",
    "# 기존에 lst 파일이 있으면 삭제 합니다.        \n",
    "delete_file(train_lst_name)        \n",
    "delete_file(val_lst_name)        \n",
    "delete_file(test_lst_name)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.lst, val.lst, test.lst 파일을 생성 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = pathlib.Path(\"./data_structured\").rglob(\"*.jpg\")\n",
    "\n",
    "for idx, p in enumerate(image_paths): # p: data_structured/test/giraffe/000000354291.jpg\n",
    "    image_id = f\"{idx:010}\" # idx 숫자 앞에 0을 채우면서 총 10자리의 문자를 생성 (에: 0000000001)\n",
    "    category = category_ids[p.parts[-2]] # category 추출하여 ID 추출 (예: giraffe --> 7)\n",
    "    path = p.as_posix()\n",
    "    split = p.parts[-3] # train, val, test 중의 하나임. (예: p: data_structured/test/giraffe/000000354291.jpg --> test)\n",
    "    with open(f\"{split}.lst\", \"a\") as f: # 예로 train.lst 파일에 쓰기\n",
    "        line = f\"{image_id}\\t{category}\\t{path}\\n\" # image_id, category_id, 이미지 경로 지정\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성된 파일의 내용을 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000000\t7\tdata_structured/test/giraffe/000000354291.jpg\n",
      "0000000001\t7\tdata_structured/test/giraffe/000000214701.jpg\n",
      "0000000002\t7\tdata_structured/test/giraffe/000000564688.jpg\n"
     ]
    }
   ],
   "source": [
    "!head -n3 test.lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000000275\t7\tdata_structured/train/giraffe/000000507557.jpg\n",
      "0000000276\t7\tdata_structured/train/giraffe/000000185716.jpg\n",
      "0000000277\t7\tdata_structured/train/giraffe/000000473952.jpg\n"
     ]
    }
   ],
   "source": [
    "!head -n3 train.lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000002475\t7\tdata_structured/val/giraffe/000000464178.jpg\n",
      "0000002476\t7\tdata_structured/val/giraffe/000000444464.jpg\n",
      "0000002477\t7\tdata_structured/val/giraffe/000000513099.jpg\n"
     ]
    }
   ],
   "source": [
    "!head -n3 val.lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: lst 파일을 생성하기 위해 im2rec.py script 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_url = \"https://raw.githubusercontent.com/apache/incubator-mxnet/master/tools/im2rec.py\"\n",
    "urllib.request.urlretrieve(script_url, \"im2rec.py\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같은 형식으로 생성 합니다.\n",
    "\n",
    "`python im2rec.py --list --recursive LST_FILE_PREFIX DATA_DIR`\n",
    "* --list - generate an LST file\n",
    "* --recursive - looks inside subfolders for image data\n",
    "* LST_FILE_PREFIX - choose the name you want for the `.lst` file\n",
    "* DATA_DIR - relative path to directory with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bear 0\n",
      "bird 1\n",
      "cat 2\n",
      "cow 3\n",
      "dog 4\n",
      "elephant 5\n",
      "frog 6\n",
      "giraffe 7\n",
      "horse 8\n",
      "sheep 9\n",
      "zebra 10\n"
     ]
    }
   ],
   "source": [
    "!python im2rec.py --list --recursive train data_structured/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bear 0\n",
      "bird 1\n",
      "cat 2\n",
      "cow 3\n",
      "dog 4\n",
      "elephant 5\n",
      "frog 6\n",
      "giraffe 7\n",
      "horse 8\n",
      "sheep 9\n",
      "zebra 10\n"
     ]
    }
   ],
   "source": [
    "!python im2rec.py --list --recursive val data_structured/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.lst` 파일을 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\t9.000000\tsheep/000000574928.jpg\n",
      "121\t0.000000\tbear/000000359337.jpg\n",
      "474\t2.000000\tcat/000000186635.jpg\n",
      "877\t4.000000\tdog/000000187167.jpg\n",
      "1840\t9.000000\tsheep/000000090683.jpg\n",
      "536\t2.000000\tcat/000000333929.jpg\n",
      "1769\t8.000000\thorse/000000422878.jpg\n",
      "1104\t5.000000\telephant/000000262979.jpg\n",
      "1174\t5.000000\telephant/000000460403.jpg\n",
      "1139\t5.000000\telephant/000000362284.jpg\n"
     ]
    }
   ],
   "source": [
    "!head train.lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Application/x-recordio (권장 format)\n",
    "___\n",
    "- 이 형식은 일반적으로 RecordIO라고 합니다. '.rec' 접미사가 있는 각 훈련 및 검증 데이터 세트에 대한 새 파일을 생성합니다. \n",
    "- `.rec` 파일은 데이터 세트의 모든 이미지를 포함하는 단일 파일이므로 수천 개의 개별 파일 전송과 관련된 오버헤드 없이 SageMaker 훈련 알고리즘으로 직접 스트리밍할 수 있습니다. \n",
    "- 이미지가 많은 데이터 세트의 경우 SageMaker가 훈련 알고리즘을 실행하기 전에 모든 이미지 파일을 다운로드할 필요가 없기 때문에 훈련 시간이 크게 단축됩니다. \n",
    "    - S3의 스트리밍으로 데이타를 다운로드 받는 \"Pipe\" 모드를 사용합니다.\n",
    "- 'im2rec.py' 스크립트를 사용하면 이미지 크기도 자동으로 조정됩니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) application/x-image 의 Option 2 먼저 실행 하고, 결과인 LST files 을 복사\n",
    "application/x-image 의 Option 2 가 실행이 안되었다면 먼저 실행 해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "new_folder_name = \"data_recordio\"\n",
    "\n",
    "# data_recordio 폴더가 존재하면 삭제 합니다.\n",
    "if os.path.isdir(new_folder_name): \n",
    "    shutil.rmtree(new_folder_name)\n",
    "    print(f\"{new_folder_name} is deleted\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### data_recordio 폴더 생성 및 train.lst, val.lst 복사 함.\n",
    "- RecordIO 파일을 만들시에 lst 파일의 내용을 이용 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordio_dir = pathlib.Path(\"./data_recordio\")\n",
    "recordio_dir.mkdir(exist_ok=True)\n",
    "shutil.copy(\"train.lst\", \"data_recordio/\")\n",
    "shutil.copy(\"val.lst\", \"data_recordio/\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) .rec 파일들을 RecordIO 포맷으로 생성하기\n",
    "\n",
    "아래와 같은 규칙으로 im2rec.py 를 실행 합니다.\n",
    "\n",
    "`python im2rec.py --resize 224 --quality 90 --num-thread 16 LST_FILE_PREFIX DATA_DIR/`\n",
    "* **--resize**: 파일을 모두 `.rec` 파일에 저장하기 전에 스크립트가 파일 크기를 조정하도록 합니다. 이미지 분류 알고리즘의 경우 기본 크기는 224x224입니다. 지금 크기를 조정하면 `.rec` 파일의 크기도 줄어듭니다.\n",
    "* **--quality**: 기본 설정은 이미지 데이터를 압축하지 않고 저장합니다. 약간의 압축을 추가하면 특히 크기를 조정하지 않는 경우 `.rec`의 파일 크기를 작게 유지합니다.\n",
    "* **--num_thread**: 작업을 병렬화할 스레드 수 설정\n",
    "* **--LST_FILE_PREFIX**: `.rec` 파일을 생성하기 위해 참조하는 `.lst`의 이름\n",
    "* **--DATA_DIR**: `.lst` 파일에 나열된 데이터가 있는 상대 경로 디렉토리\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 rec 를 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating .rec file from /home/ec2-user/SageMaker/ml-data-prep-workshop/image-classificaton/data_recordio/train.lst in /home/ec2-user/SageMaker/ml-data-prep-workshop/image-classificaton/data_recordio\n",
      "time: 0.028966426849365234  count: 0\n",
      "time: 0.4975893497467041  count: 1000\n",
      "time: 0.41789913177490234  count: 2000\n"
     ]
    }
   ],
   "source": [
    "!python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/train data_structured/train\n",
    "# !python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/train ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 rec 를 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating .rec file from /home/ec2-user/SageMaker/ml-data-prep-workshop/image-classificaton/data_recordio/val.lst in /home/ec2-user/SageMaker/ml-data-prep-workshop/image-classificaton/data_recordio\n",
      "time: 0.008013010025024414  count: 0\n"
     ]
    }
   ],
   "source": [
    "!python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/val data_structured/val\n",
    "# !python im2rec.py --resize 224 --quality 90 --num-thread 16 data_recordio/val ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. S3에 업로드 하기 \n",
    "___\n",
    "SageMaker의 내장 알고리즘이 데이터를 학습하려면 S3 버킷에 저장해야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-ap-northeast-2-057716757052\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .rec 파일을 S3 업로드 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "built_in_prefix = 'data_prep_workshop/built-in'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_builtin_s3_uri: \n",
      " s3://sagemaker-ap-northeast-2-057716757052/data_prep_workshop/built-in/data/train/train.rec\n"
     ]
    }
   ],
   "source": [
    "s3_uploader = sagemaker.s3.S3Uploader()\n",
    "\n",
    "data_path = recordio_dir / \"train.rec\"\n",
    "\n",
    "train_s3_uri = f's3://{bucket_name}/{built_in_prefix}/data/train'\n",
    "train_builtin_s3_uri = s3_uploader.upload(\n",
    "    local_path=data_path.as_posix(), desired_s3_uri= train_s3_uri\n",
    ")\n",
    "print(\"train_builtin_s3_uri: \\n\", train_builtin_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_builtin_s3_uri: \n",
      " s3://sagemaker-ap-northeast-2-057716757052/data_prep_workshop/built-in/data/val/val.rec\n"
     ]
    }
   ],
   "source": [
    "data_path = recordio_dir / \"val.rec\"\n",
    "\n",
    "val_s3_uri = f's3://{bucket_name}/{built_in_prefix}/data/val'\n",
    "val_builtin_s3_uri = s3_uploader.upload(\n",
    "    local_path=data_path.as_posix(), desired_s3_uri= val_s3_uri\n",
    ")\n",
    "print(\"val_builtin_s3_uri: \\n\", val_builtin_s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-03 09:07:19   60641456 data_prep_workshop/built-in/data/train/train.rec\n",
      "2022-01-03 09:07:20    7808476 data_prep_workshop/built-in/data/val/val.rec\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {train_builtin_s3_uri} --recursive\n",
    "! aws s3 ls {val_builtin_s3_uri} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다음 노트북에서 사용할 변수 저장\n",
    "- 아래는 다음 노트북에서 변수를 사용하기 위해 저장 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bucket_name' (str)\n",
      "Stored 'train_builtin_s3_uri' (str)\n",
      "Stored 'val_builtin_s3_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store bucket_name\n",
    "%store train_builtin_s3_uri\n",
    "%store val_builtin_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. 다음 단계\n",
    "훈련 및 검증 데이터가 S3에 업로드되었으므로 다음 노트북은 SageMaker의 내장 이미지 분류 알고리즘을 사용하여 딥 러닝 모델을 훈련하여 동물 이미지를 분류합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
